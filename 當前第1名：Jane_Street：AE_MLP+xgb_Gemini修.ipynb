{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4MMuy/E2C/IV7SwmXEmqQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanpolend/machine-learning/blob/master/%E7%95%B6%E5%89%8D%E7%AC%AC1%E5%90%8D%EF%BC%9AJane_Street%EF%BC%9AAE_MLP%2Bxgb_Gemini%E4%BF%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Jane Street Market Prediction 完整範例程式碼\"\"\"\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 資料處理與機器學習套件\n",
        "!pip install janestreet  # 安裝janestreet套件\n",
        "import os, gc\n",
        "import cudf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import janestreet\n",
        "\n",
        "# 模型與評估\n",
        "import xgboost as xgb\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "from hyperopt.pyll.base import scope\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# 深度學習相關\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(2212)\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Activation, GaussianNoise\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# 輔助工具\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from joblib import dump, load\n",
        "\n",
        "# 環境設定\n",
        "TEST = False  # 設為False執行完整訓練\n",
        "\n",
        "# ========== 自定義函數與類別 ==========\n",
        "class PurgedGroupTimeSeriesSplit:\n",
        "    \"\"\"時間序列交叉驗證實現\"\"\"\n",
        "    def __init__(self, n_splits=5, group_gap=31):\n",
        "        self.n_splits = n_splits\n",
        "        self.group_gap = group_gap\n",
        "\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        n_samples = len(X)\n",
        "        indices = np.arange(n_samples)\n",
        "        group_array = np.array(groups)\n",
        "        unique_groups = np.unique(group_array)\n",
        "        n_groups = len(unique_groups)\n",
        "        gap_size = self.group_gap * n_groups // self.n_splits\n",
        "        split_idx = []\n",
        "        for i in range(self.n_splits):\n",
        "            test_group_idx = np.arange(i * n_groups // self.n_splits, (i + 1) * n_groups // self.n_splits)\n",
        "            test_groups = unique_groups[test_group_idx]\n",
        "            test_idx = np.where(np.isin(group_array, test_groups))[0]\n",
        "            train_groups = np.setdiff1d(unique_groups, test_groups)\n",
        "            train_groups = train_groups[train_groups < np.min(test_groups) - gap_size]\n",
        "            train_idx = np.where(np.isin(group_array, train_groups))[0]\n",
        "            split_idx.append((train_idx, test_idx))\n",
        "        return split_idx\n",
        "\n",
        "def weighted_average(a):\n",
        "    \"\"\"加權平均計算\"\"\"\n",
        "    w = [1/(2**(len(a)+1-j)) if j>1 else 1/(2**len(a)) for j in range(1,len(a)+1)]\n",
        "    return np.average(a, weights=w)\n",
        "\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\"記憶體優化函數\"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(f'記憶體用量從 {start_mem:.2f} MB 減少至 {end_mem:.2f} MB')\n",
        "    return df\n",
        "\n",
        "def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls=1e-2, lr=1e-3):\n",
        "    \"\"\"自編碼器+MLP混合模型\"\"\"\n",
        "    # 輸入層\n",
        "    inp = Input(shape=(num_columns,))\n",
        "    x0 = BatchNormalization()(inp)\n",
        "\n",
        "    # 自編碼器部分\n",
        "    encoder = GaussianNoise(0.1)(x0)\n",
        "    encoder = Dense(hidden_units[0])(encoder)\n",
        "    encoder = BatchNormalization()(encoder)\n",
        "    encoder = Activation('swish')(encoder)\n",
        "\n",
        "    # 解碼器\n",
        "    decoder = Dropout(dropout_rates[0])(encoder)\n",
        "    decoder = Dense(num_columns, name='decoder')(decoder)\n",
        "\n",
        "    # 多任務學習頭\n",
        "    x = K.concatenate([x0, encoder])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rates[1])(x)\n",
        "\n",
        "    # 隱藏層堆疊\n",
        "    for i in range(2, len(hidden_units)):\n",
        "        x = Dense(hidden_units[i])(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('swish')(x)\n",
        "        x = Dropout(dropout_rates[i])(x)\n",
        "\n",
        "    # 輸出層\n",
        "    outputs = []\n",
        "    for _ in range(num_labels):\n",
        "        outputs.append(Dense(1, activation='sigmoid')(x))\n",
        "\n",
        "    # 模型編譯\n",
        "    model = Model(inputs=inp, outputs=[decoder] + outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=['mse'] + [tf.keras.losses.BinaryCrossentropy(label_smoothing=ls) for _ in range(num_labels)],\n",
        "        metrics=[tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ========== 主要執行流程 ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # 資料載入與預處理\n",
        "    print('\\n[1/5] 載入資料...')\n",
        "    train = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\n",
        "    features = [c for c in train.columns if 'feature' in c]\n",
        "    train = train.to_pandas()\n",
        "\n",
        "    print('\\n[2/5] 資料清洗...')\n",
        "    train = train.query('date > 85 and weight > 0').reset_index(drop=True)\n",
        "    train[features] = train[features].fillna(method='ffill').fillna(0)\n",
        "    train['action'] = ((train[['resp','resp_1','resp_2','resp_3','resp_4']] > 0).all(axis=1)).astype(int)\n",
        "    resp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\n",
        "\n",
        "    # 特徵工程\n",
        "    print('\\n[3/5] 特徵工程...')\n",
        "    X = train[features].values\n",
        "    y = np.stack([(train[c] > 0).astype(int) for c in resp_cols]).T\n",
        "    sw = np.mean(np.abs(train[resp_cols].values), axis=1)\n",
        "\n",
        "    # 模型參數\n",
        "    params = {\n",
        "        'num_columns': len(features),\n",
        "        'num_labels': 5,\n",
        "        'hidden_units': [96, 96, 896, 448, 448, 256],\n",
        "        'dropout_rates': [0.035, 0.038, 0.424, 0.104, 0.492, 0.320, 0.272, 0.438],\n",
        "        'ls': 0,\n",
        "        'lr': 1e-3,\n",
        "    }\n",
        "\n",
        "    # 訓練流程\n",
        "    if not TEST:\n",
        "        print('\\n[4/5] 開始訓練...')\n",
        "        scores, models = [], []\n",
        "        gkf = PurgedGroupTimeSeriesSplit(n_splits=5, group_gap=31)\n",
        "\n",
        "        for fold, (tr_idx, val_idx) in enumerate(gkf.split(X, groups=train['date'])):\n",
        "            print(f'\\n--- Fold {fold+1}/5 ---')\n",
        "            X_tr, X_val = X[tr_idx], X[val_idx]\n",
        "            y_tr, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "            # 模型初始化\n",
        "            model = create_ae_mlp(**params)\n",
        "            checkpoint = ModelCheckpoint(f'best_model_fold{fold}.h5', save_best_only=True, monitor='val_auc', mode='max')\n",
        "            early_stop = EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max')\n",
        "\n",
        "            # 訓練執行\n",
        "            history = model.fit(\n",
        "                X_tr, [X_tr] + [y_tr[:,i] for i in range(5)],\n",
        "                validation_data=(X_val, [X_val] + [y_val[:,i] for i in range(5)]),\n",
        "                epochs=100,\n",
        "                batch_size=4096,\n",
        "                callbacks=[checkpoint, early_stop],\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # 模型評估\n",
        "            model.load_weights(f'best_model_fold{fold}.h5')\n",
        "            val_pred = np.mean([model.predict(X_val, batch_size=4096)[i+1] for i in range(5)], axis=0)\n",
        "            score = roc_auc_score(y_val.mean(axis=1), val_pred)\n",
        "            scores.append(score)\n",
        "            models.append(model)\n",
        "            print(f'Fold {fold+1} AUC: {score:.5f}')\n",
        "            gc.collect()\n",
        "\n",
        "        # 最終評估\n",
        "        print('\\n[5/5] 訓練完成')\n",
        "        print(f'各Fold分數: {scores}')\n",
        "        print(f'加權平均分數: {weighted_average(scores):.5f}')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "V2xH1staatBA",
        "outputId": "55b07306-7f10-4f62-d6c7-c8191022006f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement janestreet (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for janestreet\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'janestreet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e3a332e7e72d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjanestreet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 模型與評估\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'janestreet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}